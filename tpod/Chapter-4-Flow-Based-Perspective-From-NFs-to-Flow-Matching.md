# 第 4 章 流视角：从归一化流到流匹配

> *万物皆流。*  
> —— Heraclitus

*变量替换公式*是概率论的基石之一，在现代生成建模中焕发新生。Score SDE 通过 Fokker–Planck 方程在数据分布与先验分布之间架起微分方程框架，而这种连续演化本质上正是同一基本原理的动态形式。

**密度的变量替换公式。** 给定可逆变换 $f$，在 $z \sim p_{\text{prior}}$ 时 $x = f(z)$ 的密度为：

$$
p(x) = p_{\text{prior}}(z) \left| \det \frac{\partial f^{-1}(x)}{\partial x} \right|, \quad \text{其中 } z = f^{-1}(x).
$$

当 $f$ 易于处理时，这一看似简单的公式实现了密度与样本的精确、双向传输，构成了归一化流（Normalizing Flows）的基础。若从连续时间变换的角度重新审视这一思想呢？

本章将基于这一核心原理，探讨扩散模型的一种新视角：**流匹配（Flow Matching, FM）**。流匹配自然地从（连续）归一化流中发展而来，深化了我们将扩散理解为一种密度传输过程的认识。

为便于理解本章，附录中给出了变量替换公式不同形式的直观、自洽概述，从基本情形逐步推进到连续性方程，最后到 Fokker–Planck 方程。

---

## 4.1 流式模型：归一化流与神经常微分方程

本节介绍流式模型，包括**归一化流（NFs）**与**神经常微分方程（NODEs）**。

NFs 通过对简单基分布施加一系列可逆变换，实现灵活且易处理的概率密度估计。NODEs 将该框架推广到连续时间，其中变换由 ODE 刻画。将变换视为连续时间动力学后，NODEs 为 NF 范式提供了平滑、可扩展的延伸。

![可逆映射下 NF 样本运动的示意图](../arXiv-2510.21890v1/Images/PartB/flow_density.pdf)

**图 1：可逆映射下 NF 样本运动的示意图。** 由一系列可逆函数 $f: z \mapsto x$ 将潜变量 $z$ 变为数据 $x$，并配有逆映射 $f^{-1}: x \mapsto z$ 重建数据。NF 类似编码器–解码器结构，但编码器为光滑可逆映射，解码器恰为其逆。密度的相应变化可由变量替换公式计算。

### 4.1.1 归一化流

NFs 通过可逆映射将简单先验 $p_{\text{prior}}(z)$（如标准高斯 $\mathcal{N}(0, I)$）变换为复杂数据分布 $p_{\text{data}}(x)$ 进行建模，其中 $x = f_\phi(z)$、$z \sim p_{\text{prior}}$。此处 $x$ 与 $z$ 维数相同。由变量替换公式，模型似然为[^1]

$$
\log p_\phi(x) = \log p_{\text{prior}}(z) + \log \left| \det \frac{\partial f_\phi^{-1}(x)}{\partial x} \right|.
$$

[^1]: 若进一步限制映射为凸势的梯度，则该式可化为 Monge–Ampère 关系，在二次成本下刻画将一分布最优变换为另一分布。

**训练目标。** 参数 $\phi$ 通过最大化数据上的似然学习：

$$
\mathcal{L}_{\text{NF}}(\phi) = \mathbb{E}_{x \sim p_{\text{data}}} \left[ \log p_\phi(x) \right].
$$

Jacobian 行列式的计算一般具有 $\mathcal{O}(D^3)$ 量级的代价。

**构造可逆变换。** 单一复杂可逆网络因其 Jacobian 行列式而代价高昂；反之，简单变换（如线性）高效但表达能力有限。为折中，NFs 采用 $K$ 个可训练可逆映射 $\{f_k\}_{k=0}^{L-1}$ 的序列，每个映射的 Jacobian 可高效计算：

$$
f_\phi = f_{L-1} \circ f_{L-2} \circ \cdots \circ f_0.
$$

每个 $f_k$ 由神经网络参数化。样本按

$$
x_{k+1} = f_k(x_k), \quad k = 0, \ldots, L-1,
$$

变换，其中 $z=x_0 \sim p_{\text{prior}}$、$x = x_L$ 对应数据。得到的（对数）密度为

$$
p_\phi(x) = p_{\text{prior}}(x_0) \prod_{k=0}^{L-1} \left| \det \frac{\partial f_k}{\partial x_k} \right|^{-1}, \quad \text{或等价地，}
$$
$$
\log p_\phi(x) = \log p_{\text{prior}}(x_0) + \sum_{k=0}^{L-1} \log \left| \det \frac{\partial f_k}{\partial x_k} \right|^{-1}.
$$

**图 2：归一化流示意图。** NF 由可逆映射的堆叠构成 $f_\phi = f_{L-1} \circ \cdots \circ f_0$。变换将潜样本 $x_0 \sim p_{\mathrm{prior}}$ 映射为数据样本 $x_L \sim p_{\mathrm{data}}$。

**可逆流的例子。** 下面介绍两类代表：**Planar Flows** 与 **Residual Flows**。

- **Planar Flows：** 采用简单变换 $f(z) = z + u h(w^\top z + b)$，其中 $u, w \in \mathbb{R}^D$，$b \in \mathbb{R}$，$h(\cdot)$ 为激活函数。Jacobian 行列式为 $\left| 1 + u^\top h'(w^\top z + b) w \right|$。

- **Residual Flows：** 将变换 $f$ 定义为 $f(z) = z + v(z)$，其中 $v$ 为压缩映射（Lipschitz 常数 $< 1$）。由 Banach 不动点定理保证可逆性。Jacobian 的对数行列式可化为迹展开，可通过迹估计器高效计算。

**采样与推断。** 从 NFs 采样是直接的：抽取 $x_0 \sim p_{\text{prior}}$ 并计算 $x = f_\phi(x_0)$。精确似然由上式得到。

### 4.1.2 神经常微分方程

![离散与连续时间归一化流对比](../arXiv-2510.21890v1/Images/PartB/discrete_vs_continuous_side_by_side_white.pdf)

**图 3：离散与连续时间归一化流对比。** （左）离散 NF 通过有限个可逆映射传输样本；（右）连续 NF（Neural ODE）沿积分曲线演化状态。

**从离散时间 NF 到连续时间 NF（神经常微分方程）。** 结合残差流形式，每一层可写成 $x_{k+1} = x_k + v_{\phi_k}(x_k, k)$，其中 $v_{\phi_k}(\cdot, k)$ 为由神经网络参数化的、与层相关的速度场。该形式对应可学习参数 $\phi$ 的连续时间 ODE 的 Euler 离散化：

$$
\frac{\mathrm{d} x(t)}{\mathrm{d} t} = v_\phi(x(t), t).
$$

在层数趋于无穷、步长趋于零的极限下，离散 NF 收敛到连续模型，得到**神经常微分方程（NODEs）**的框架，也称为**连续归一化流（CNFs）**。

**Neural ODE 的形式设定。** Neural ODE 通过下式定义连续变换：

$$
\frac{\mathrm{d} x(t)}{\mathrm{d} t} = v_\phi(x(t), t),\quad t\in [0,T]
$$

其中 $x(t) \in \mathbb{R}^D$ 为时刻 $t$ 的状态；$v_\phi(x(t), t)$ 为由 $\phi$ 参数化的神经网络。

**NODE 的目标。** 从初始条件 $x(0) \sim p_{\text{prior}}$ 出发，ODE 随时间连续演化状态，诱导一族边缘分布 $p_\phi(x_t, t)$。目标是学习神经向量场 $v_\phi$，使得 $t=T$ 处的终端分布与目标分布 $p_{\mathrm{data}}(\cdot)$ 匹配。

**连续时间变量替换公式。** 对于在以上 ODE 下演化的过程的时变密度，**瞬时变量替换公式**为：

$$
\frac{\mathrm{d}}{\mathrm{d} t} \log p_\phi(x(t), t) = -\nabla_x\cdot v_\phi(x(t), t).
$$

因此，给定先验，终端状态 $x(T)$ 的对数密度为

$$
\log p_\phi(x(T), T) = \log p_{\text{prior}}(x(0), 0) - \int_0^T \nabla_x \cdot v_\phi(x(t), t)   \mathrm{d}t.
$$

该式通过对 ODE 进行数值求解可实现精确似然计算。该瞬时变量替换公式是 Fokker–Planck 方程的特例，即其确定性形式，称为**连续性方程**。

**引理（瞬时变量替换）** 设 $z(t)$ 为具有时变密度 $p(z(t), t)$ 的连续随机过程，并设其按 ODE $\frac{\mathrm{d} z(t)}{\mathrm{d} t} = F(z(t), t)$ 演化。若 $F$ 对 $z$ 一致 Lipschitz、对 $t$ 连续，则对数密度对时间的导数满足 $\frac{\partial \log p(z(t), t)}{\partial t} = -\nabla_z \cdot F(z(t), t)$。

**训练 NODEs。** 基于上式，NODEs 学习参数化速度场 $v_\phi$，使得终端分布 $p_\phi(\cdot, T) \approx p_{\text{data}}$。训练遵循 MLE 框架。为计算数据点的对数似然，对变量替换公式积分；先验项对标准分布易算。最大化损失需通过 ODE 求解器反向传播；伴随灵敏度方法以 $\mathcal{O}(1)$ 内存复杂度计算梯度。

**用 NODEs 推断。** 使用训练好的模型采样时，抽取 $x(0) \sim p_{\text{prior}}$ 并前向积分；终端状态近似为 $p_{\text{data}}$ 的样本。散度可用随机迹估计器（如 Hutchinson 估计器）高效估计。

---

## 4.2 流匹配框架

Score SDE 与 NODEs 为生成建模提供了另一种视角：学习连续时间流（随机或确定性），将简单高斯先验样本传输为来自 $p_{\text{data}}$ 的类数据样本。

**流匹配（FM）** 框架建立在这一思想上，但将其推广为学习两个*任意*固定端点分布之间的流：源分布 $p_{\text{src}}$ 与目标分布 $p_{\text{tgt}}$，均假设易于采样。当 $p_{\text{src}}$ 为高斯时，称该设定为**高斯流匹配**。与经典扩散模型相比，FM 仅用端点样本即可对一大类传输问题实现高效、无仿真的训练。

### 4.2.1 从基于分数方法的启示

我们以稍不同但等价的表述重访 Score SDE 框架，以提炼推动 FM 方法的关键洞见。

**步骤 1：定义条件路径及其边缘密度。**

![条件转移分布的示意图](../arXiv-2510.21890v1/Images/PartB/data_vs_prior_cone_with_oval.pdf)

**图 4：条件转移分布的示意图。** $p_t(x_t | x_0) = \mathcal{N}(x_t;\alpha_t x_0,\sigma_t^2 I)$ 定义了一条从数据样本指向高斯先验的（高斯）条件概率路径。

扩散模型指定连续时间密度族 $\{p_t\}_{t \in [0,1]}$，将 $t=1$ 处的简单先验作为源，传输到 $t=0$ 处的目标数据分布。该路径由前向条件分布隐式定义 $p_t(x_t|x_0) = \mathcal{N}(x_t; \alpha_t x_0, \sigma_t^2 I)$，并诱导边缘密度 $p_t(x_t) := \int p_t(x_t |x_0) p_{\text{data}}(x_0) \mathrm{d}x_0$。条件高斯方差的增大驱动 $p_t$ 向高斯先验演化。

**步骤 2：速度场。** 边缘密度 $p_t$ 的时间演化由从 Fokker–Planck 方程导出的速度场刻画：

$$
v_t(x) := f(t)x - \frac{1}{2}g^2(t)\nabla_x \log p_t(x),
$$

其通过 PF-ODE 定义确定性粒子流。标量函数 $f(t)$ 与 $g(t)$ 由相应前向 SDE 的系数决定。

**步骤 3：通过条件策略学习。** 目标是用神经网络通过期望平方误差逼近真实速度场。由于边缘分数不可得，我们利用易处理的条件分布定义条件速度；由全期望律可得到替代训练目标（DSM），其最小化元等于边缘分数，从而验证了条件训练目标。

![扩散中条件视角与边缘视角的示意图](../arXiv-2510.21890v1/Images/PartB/four_panel_simple.pdf)

**图 5：扩散中条件视角与边缘视角的示意图。** (1) 条件高斯路径；(2) 条件速度；(3) 边缘密度；(4) 边缘速度。在单侧条件的 FM 框架下，同一示意图适用于条件与边缘速度。

**基本法则：Fokker–Planck 方程。** 边缘密度 $p_t$ 按 Fokker–Planck 方程演化；该 PDE 保证 PF-ODE 给出的密度与前向 SDE 的边缘分布一致。从 $x_1 \sim p_{\mathrm{prior}}$ 出发、将 PF-ODE 从 $t=1$ 反向积分到 $t=0$，由前推公式得到时变密度；Fokker–Planck 方程保证诱导的密度路径与同一演化密度一致，从而在 $t=0$ 恢复数据分布。

### 4.2.2 流匹配框架

**步骤 1：定义条件路径及其边缘密度。** 考虑任意源与目标概率分布 $p_{\mathrm{src}}$ 和 $p_{\mathrm{tgt}}$。设 $p_0 = p_{\mathrm{src}}$，$p_1 = p_{\mathrm{tgt}}$（FM 文献中 $t=0$ 对应源，$t=1$ 对应目标）。FM 隐式定义在这些端点之间插值的连续中间密度族 $\{p_t\}$。每个边缘 $p_t$ 由潜变量 $\mathbf{z} \sim \pi(\mathbf{z})$ 及条件分布 $p_t(x_t | z)$ 表出：$p_t(x_t) = \int p_t(x_t | z) \pi(z) \mathrm{d} z$。$\mathbf{z}$ 的常见选择包括：**双侧条件** $\mathbf{z} = (x_0, x_1)$；**单侧条件** $\mathbf{z} = x_0$ 或 $x_1$。条件分布 $p_t(x_t|z)$ 应具有易处理的闭式表达式。

**步骤 2：速度场。** 目标是找到速度场 $v_t(x)$，使得其诱导的 ODE 在从源前向积分或从目标反向积分时，边缘分布在每个时刻 $t$ 与 $p_t$ 一致。该要求由**连续性方程**刻画：

$$
\frac{\partial p_t(x)}{\partial t} + \nabla \cdot \big( v_t(x) p_t(x) \big) = 0.
$$

满足该方程的任意速度场都保证 ODE 流以恰好沿预定 $p_t$ 的方式传输样本。直观上，许多不同的流可诱导相同的边缘演化（方程有无穷多解）；FM 寻求满足连续性方程的特定速度场。

**步骤 3：通过条件策略学习。** FM 训练的目标是用神经网络 $v_\phi$ 通过最小化期望平方误差逼近真实速度场 $v_t$。我们将该神经网络参数化称为 **$v$-预测**（速度预测）。与基于分数的情形相同，真实速度一般不可处理；引入潜变量 $z \sim \pi(z)$ 并定义条件速度场 $v_t(x|z)$，可由全期望律将损失重写为**条件流匹配（CFM）**损失加常数。即，最小化 FM 损失等价于最小化 CFM 损失。为使 CFM 实现易处理、无仿真的训练，需满足：(i) 从条件概率路径的采样简单；(ii) 条件速度有简单闭式。边缘速度可由条件速度场边缘化得到；可以证明 CFM 目标的最小化元恢复该边缘速度。因此，学习匹配条件速度场即足以恢复有效的无条件速度场。

**定理（$\mathcal{L}_{\mathrm{FM}}$ 与 $\mathcal{L}_{\mathrm{CFM}}$ 的等价性）** $\mathcal{L}_{\mathrm{FM}}(\phi) = \mathcal{L}_{\mathrm{CFM}}(\phi) + C$，且两个损失的最小化元 $v^*$ 满足 $v^*(x_t, t) = v_t(x_t)$（对几乎所有 $x_t \sim p_t$）。

这是条件技巧得到易处理训练目标的第三处实例；变分、基于分数与基于流的途径都体现同一基本原理。

### 4.2.3 扩散模型、一般流匹配与 NODEs 的比较

**扩散模型与一般流匹配的比较。** 从基于分数的启示可得到保留相同基本原理的推广 FM 框架。下表总结扩散模型（或高斯 FM）与一般 FM 的对比。

**表 1：扩散模型（或高斯 FM）与一般 FM 框架的比较**

| 方面 | 扩散模型 | 一般 FM |
|------|----------|---------|
| 源分布 $p_{\mathrm{src}}$ | 高斯先验 | 任意 |
| 目标分布 $p_{\mathrm{tgt}}$ | 数据分布 | 任意 |
| 潜分布 $\pi(z)$ | $p_{\text{data}}$ | 见 4.3.2 节 |
| 条件分布 $p_t(x_t|z)$ | $\mathcal{N}(x_t;\alpha_t x_0,\sigma_t^2 I)$ | 见 4.3.2 节 |
| 学习目标 | $\mathcal{L}_{\text{SM}}=\mathcal{L}_{\text{DSM}}+C$ | $\mathcal{L}_{\mathrm{FM}}=\mathcal{L}_{\mathrm{CFM}}+C$ |
| 基本法则 | Fokker-Planck / 连续性方程 | 同上 |

由于高斯 FM 与标准扩散模型本质等价，除非特别说明我们将不对二者区分。

**与 NODEs 的联系。** FM 可视为 NODEs 的无仿真替代。CNFs 在最大似然训练中需求解 ODE，计算昂贵；FM 通过简单回归损失直接回归预定速度场绕过这一点。关键洞见是：当连接源与目标分布的边缘密度路径固定时，训练中的精确仿真不再必要。

### 4.2.4 （可选）基本法则

**连续性方程：质量守恒准则。** 与 4.2.1 中 PF-ODE 与 Fokker–Planck 的分析类似，下面给出一个准则，用于验证 ODE 流诱导的密度路径是否与给定的路径 $\{p_t\}_{t \in [0,1]}$ 一致。

考虑在时变速度场 $v_t$ 下粒子流的 ODE：
$$
\frac{\mathrm{d} x(t)}{\mathrm{d} t} = v_t(x(t)).
$$
该 ODE 对任意 $s,t \in [0,1]$ 定义了流映射 $\Psi_{s \to t}(x_0)$，特别地，将 $t=0$ 时刻的初值 $x_0 \sim p_{\mathrm{src}}$ 传输到时刻 $t$ 的状态。时刻 $t$ 的诱导分布由前推给出：
$$
p_t^{\mathrm{fwd}}(x) = \int \delta(x - \Psi_{0\to t}(x_0))\, p_{\mathrm{src}}(x_0) \mathrm{d}x_0 =: (\Psi_{0\to t})_\# p_{\mathrm{src}},
$$
因此当 $x_0 \sim p_{\mathrm{src}}$ 时有 $\Psi_{0\to t}(x_0) \sim p_t^{\mathrm{fwd}}$。类似地，可从 $x_1 \sim p_{\mathrm{tgt}}$ 经 $\Psi_{1\to 0}(x_1)$ 反向传输到 $p_{\mathrm{src}}$。

若给定一条给定的密度路径 $\{p_t\}_{t \in [0,1]}$，并构造速度场 $\{v_t\}_{t \in [0,1]}$ 定义粒子流，自然的问题是：**在什么条件下，流诱导的密度 $p_t^{\mathrm{fwd}}$ 对所有 $t \in [0,1]$ 都精确等于目标密度 $p_t$？** 一旦两种密度演化一致，就可利用 ODE 流通过求解 ODE 在 $p_{\mathrm{src}}$ 与 $p_{\mathrm{tgt}}$ 之间灵活传输样本。

与 Fokker–Planck 分析类似，验证该一致性的一个原则性方式是通过**连续性方程**，它刻画了时变密度的质量守恒：

**定理（质量守恒准则）** 流诱导的密度 $p_t^{\mathrm{fwd}}$ 对所有 $t \in [0,1]$ 等于给定路径 $p_t$，即 $p_t^{\mathrm{fwd}} = p_t$，当且仅当 $(p_t, v_t)$ 满足连续性方程：
$$
\partial_t p_t(x) + \nabla_x \cdot (p_t(x) v_t(x)) = 0,
$$
对所有 $t \in [0,1]$ 与 $x$ 成立。

**从条件路径到边缘路径。** 如 4.2.2 所述，我们先定义条件概率路径 $p_t(\cdot|z)$ 及相应的条件速度场 $v_t(\cdot|z)$，再通过
$$
v_t(x) = \int v_t(x|z) \frac{p_t(x|z) \pi(z)}{p_t(x)} \mathrm{d} z
$$
构造边缘速度场。仍需保证所得边缘速度 $v_t$ 诱导的 ODE 流的密度路径与给定的 $p_t$ 一致。幸运的是，这一验证可以完全在条件层面完成：若每个条件速度场 $v_t(\cdot|z)$ 诱导条件密度路径 $p_t(\cdot|z)$，则所得边缘速度 $v_t$ 也诱导正确的边缘路径。形式地，有：

**命题（边缘速度场生成给定边缘密度）** 若条件速度场 $v_t(\cdot|z)$ 诱导的条件密度路径与 $p_t(\cdot|z)$ 一致（从 $p_0(\cdot|z)$ 出发），则由上式定义的边缘速度场 $v_t(\cdot)$ 诱导的边缘密度路径与 $p_t(\cdot)$ 一致，从 $p_0(\cdot)$ 出发。

该结论可通过验证 $(p_t, v_t)$ 满足连续性方程得到。由此可将难以处理的边缘速度场的构造约化到定义更简单的条件场 $v_t(\cdot|z)$，后者由构造更易处理。

---

## 4.3 构造分布间的概率路径与速度

流匹配的本质在于将源分布逐步变换为目标分布。要引导这一变换，需要两个要素：**概率路径** $p_t$（给出每个时刻 $t$ 演化分布的 snapshot）与**速度场** $v_t$（描述各粒子沿路径的运动）。二者由连续性方程联系。学习任务归结为找到忠实驱动该过程的速度场 $v_t$；然而对一般复杂分布，真实边缘速度未知。

**条件流匹配**的核心思想是通过构造人工但易处理的过程来应对真实边缘速度的不可处理性：引入条件变量 $z$，并设计条件速度 $v_t(x_t|z)$ 和/或条件路径 $p_t(x_t|z)$，且有意取为简单形式。这些条件对象有闭式，可作为模型回归的替代目标；只要 (i) 能从 $p_t(\cdot|z)$ 高效采样，(ii) 相应速度 $v_t(\cdot|z)$ 有闭式，即可得到有效训练损失 $\mathcal{L}_{\mathrm{CFM}}$。

两种互补视角用于构造条件路径与速度：**条件概率路径优先（Euler 视角）**——先给定条件概率路径 $p_t(\cdot|z)$，再导出相应的条件速度场；**条件流优先（Lagrangian 视角）**——先给定条件流 $\Psi_{0\to t}(\cdot|z)$（通常为仿射），再沿轨迹对时间求导得到条件速度场。4.3.2 节详述第一种方式，4.3.3 节介绍第二种。

### 4.3.1 关键特例：高斯-高斯桥中的边缘与速度

当源与目标分布均为高斯时，速度场有闭式。考虑插值边缘密度路径 $p_t(x_t) = \mathcal{N}(x_t; \mu(t), \sigma^2(t) I)$，其中时变均值 $\mu(t)$、方差 $\sigma^2(t)>0$。对该高斯路径，一个特别简单的实现为 $\Psi_{0\to t}(x) := \mu(t) + \sigma(t) (x - \mu(0))/\sigma(0)$。诱导该 ODE 流的速度场唯一且可解析刻画为：

$$
v_t(x) = \frac{\sigma'(t)}{\sigma(t)} \left( x - \mu(t) \right) + \mu'(t).
$$

对固定的流映射（流优先视角），速度由 $v_t = \partial_t \Psi_{0\to t} \circ \Psi_{0\to t}^{-1}$ 唯一确定；在此构造下 $(p_t,v_t)$ 自动满足连续性方程。反之，对给定的密度路径若不固定流映射（概率路径优先视角），速度场不唯一。

### 4.3.2 条件概率路径优先构造

先构造条件密度路径 $p_t(\cdot|z)$，再在 $\pi(z)$ 下导出相应的条件速度场（由高斯路径的闭式速度）。依 $z$ 的选取有两种自然情形：(i) **双侧** $z=(x_0,x_1)$ —「束状」路径；(ii) **单侧** $z=x_0$ 或 $x_1$ —「聚光灯状」路径。

**双侧 $z=(x_0,x_1)$。** 取 $\pi(z) = p_{\mathrm{src}}(x_0) p_{\mathrm{tgt}}(x_1)$。条件路径由固定方差 $\sigma>0$ 的线性插值定义：$p_t(x_t | z) = \mathcal{N}(x_t; a_t x_0 + b_t x_1, \sigma^2 I)$，其中 $a_t,b_t$ 满足 $a_0=1,b_0=0$ 与 $a_1=0,b_1=1$；常见取 $a_t=1-t$，$b_t=t$。在 $\sigma=0$ 时得到确定性插值路径。由闭式速度，条件速度为 $v_t(x|z) = a'_t x_0 + b'_t x_1$。此时 CFM 损失为对 $a'_t x_0 + b'_t x_1$ 的回归；最优速度场为给定 $x_t$ 时 $a'_t x_0 + b'_t x_1$ 的条件期望。

**单侧 $z=x_1$（或 $x_0$）。** 在标准生成设定 $p_{\mathrm{src}}=\mathcal{N}(0,I)$、$p_{\mathrm{tgt}}=p_{\mathrm{data}}$ 下，对固定 $x_1 \sim p_{\mathrm{data}}$ 定义 $p_t(x_t|x_1)=\mathcal{N}(x_t; b_t x_1, a_t^2 I)$，边界处 $p_0(\cdot|x_1)=\mathcal{N}(\cdot;0,I)$，$p_1(\cdot|x_1)=\delta(\cdot - x_1)$。导出的条件速度为 $v_t(x|x_1) = b'_t x_1 + (a'_t/a_t)(x - b_t x_1)$。单侧与双侧 CFM 目标共享同一最小化元。

**高斯 FM = 扩散模型。** 采用 FM 约定 $t=0$ 为源/先验、$t=1$ 为目标/数据。取 $a_t=1-t$、$b_t=t$ 即得到熟悉的 FM/RF 调度。高斯 FM 可等价理解为在线性调度下预测*速度*的扩散模型；流匹配与扩散是两种可相互转化的等价表述。

**表 2：以 FM 约定 $x_t = a_t x_0 + b_t x_1$ 写出的不同插值摘要（VE/VP 由其扩散约定经 $a_t:=\sigma_t, b_t:=\alpha_t$ 转换）**

|  | VE | VP | FM/RF | Trig. |
|---|----|----|-------|-------|
| $a_t$ (先验系数) | $a_t$ | $\sqrt{1-b_t^2}$ | $1-t$ | $\cos(\frac{\pi}{2}t)$ |
| $b_t$ (数据系数) | $1$ | $b_t$ | $t$ | $\sin(\frac{\pi}{2}t)$ |
| $p_{\text{prior}}$ | $\mathcal{N}(0,a_1^2 I)$ | $\mathcal{N}(0,I)$ | $\mathcal{N}(0,I)$ | $\mathcal{N}(0,I)$ |

### 4.3.3 条件流优先构造

考虑端点任意的情形；目标是在轨迹空间内直接设计将 $p_{\mathrm{src}}$ 的样本传输到 $p_{\mathrm{tgt}}$ 的条件流，并得到可作为回归目标的闭式 $v_t(x_t|z)$。**动机：** 可直接指定条件流映射 $\Psi_{0\to t}(\cdot;z)$，沿轨迹对时间求导即得回归目标；在具几何结构的空间上常可从几何（测地线、指数映射等）直接构造流映射。

**条件仿射流。** 固定 $z \sim \pi$，通过时变**条件仿射流**前推 $x_0 \sim p_{\mathrm{src}}$：$\Psi_{0\to t}(x_0;z) := \mu_t(z) + A_t(z) x_0$，其中 $\mu_t(z) \in \mathbb{R}^D$，$A_t(z) \in \mathbb{R}^{D \times D}$ 在 $t \in (0,1)$ 上可逆，边界 $A_0(z)=I,\ \mu_0(z)=0$ 在 $t=0$ 恢复 $p_{\mathrm{src}}$。诱导的条件路径为 $p_t(\cdot|z) = (\Psi_{0\to t}(\cdot;z))_\# p_{\mathrm{src}}$。条件速度 $v_t(\cdot|z)$ 由对 $\Psi_{0\to t}$ 关于 $t$ 求导得到；对仿射流有闭式 $v_t(x|z) = \mu_t'(z) + A_t'(z) A_t(z)^{-1}(x - \mu_t(z))$。单侧条件 $z=x_1$ 取 $\mu_t(z)=b_t z$、$A_t(z)=a_t I$ 即得到通常的 CFM 目标；双侧条件得到确定性路径与标准双侧 CFM 目标。

### 4.3.4 概率路径优先与流优先构造的对比

两种构造都旨在通过条件动力学连接源与目标分布。**概率路径优先**（Euler 视角）先设定条件密度路径 $p_t(\cdot|z)$，再导出条件速度场；**流优先**（Lagrangian 视角）先指定条件流映射，再沿轨迹求导得到速度。在正则性下二者给出等价传输，但在可辨识性、计算简便性及端点约束的施加方式上不同。当条件路径具有闭式速度时路径优先更自然；当对轨迹有强结构先验时流优先更自然。

---

## 4.4 （可选）典范仿射流的性质

给定两端点分布 $p_0=p_{\mathrm{src}}$ 与 $p_1=p_{\mathrm{tgt}}$，流匹配（FM）与整流流（RF）中定义条件路径时常用线性插值 $a_t = 1-t$、$b_t = t$，即 $x_t = (1-t)x_0 + t x_1$。在此选取下，训练目标简化为对 $\|v_\phi(x_t,t) - (x_1 - x_0)\|_2^2$ 的期望最小化。该线性流具有若干吸引人的性质；特别地，它允许一种称为 **Reflow** 的迭代改进方案，在保持边缘分布的同时逐步将分布间的路径拉直。

### 4.4.1 整流流：从噪声配对到结构化配对

**经相干路径从噪声到数据。** 考虑生成任务：$p_{\text{src}}$ 为先验，$p_{\text{tgt}}$ 为真实数据。朴素做法是独立采样源与目标并做线性插值、拟合速度场，但这会产生*不相干配对*：端点在不同迭代间无关，轨迹起伏、方差爆炸。**为何独立耦合不足：** 条件流匹配中使用独立抽取时耦合便于采样，但诱导曲折、高方差的路径。**通过依赖耦合整流流：** 用预训练扩散模型作为 PF-ODE 的漂移*确定性*地传输每个源点，得到配对 $(z_0,\hat{z}_1)$ 构成*依赖耦合*，沿结构化、模型引导的路径。

**算法：Rectify 操作**

1. **预训练扩散。** 在所选路径上拟合 $v_{\phi^*}$，最小化 $\mathbb{E}_{t,x_0,x_1}[\|v_\phi(x_t,t) - \frac{\mathrm{d} x_t}{\mathrm{d} t}\|_2^2]$。
2. **整流。** 采样 $z_0 \sim p_{\text{src}}$ 并积分 ODE $\frac{\mathrm{d} z(t)}{\mathrm{d} t} = v_{\phi^*}(z(t),t)$ 得到 $\hat{z}_1 = z(1)$ 及轨迹。
3. **输出：** 依赖（相干）配对 $(z_0,\hat{z}_1)$ 或完整轨迹。

**为何有效：保持边缘的结构。** Rectify 将每个源点与其流端点配对，得到确定性联合；源边缘保持，且沿流的前推给出时刻 $t$ 的分布。若学到的速度与给定参考路径的真实漂移一致，则所有中间边缘一致且 $(Φ_{0\to 1})_\# p_{\mathrm{src}} = p_{\mathrm{tgt}}$。**小结：** 整流用平滑的、由教师引导的轨迹替代噪声的独立配对，降低方差、简化优化、改善样本。对典范路径，重复应用 Rectify（**Reflow**）可进一步拉直轨迹而不增加传输成本。

### 4.4.2 Reflow：迭代拉直流

**为何需要 Reflow？** 独立配对常在 $p_{\text{src}}$ 与 $p_{\text{tgt}}$ 之间诱导不规则、蜿蜒的 ODE 轨迹。**核心思想：** 从乘积耦合上的典范插值出发，应用 Rectify 将独立配对替换为依赖配对，迭代该更新逐步降低路径曲率。**Reflow 步骤：** 每次迭代 (1) 从当前耦合的样本重新拟合速度场；(2) 从新源样本出发求解学到的 ODE 得到新端点，定义更新后的耦合。即 $\pi^{(k+1)} = \mathrm{Rectify}(\pi^{(k)})$，流与耦合共同演化。

### 4.4.3 Reflow 的性质

- **I. Reflow 从不增加传输成本。** 每个 Rectify 步形成新耦合，其成本不差于原耦合（由 Jensen 不等式）；递归应用表明 Reflow 过程不会增加传输成本。
- **II. Reflow 拉直路径。** 定义路径的*直线度泛函* $\mathcal{S}(\mathbf{Y})$；若 $\mathcal{S}=0$ 则路径恰为直线。对整流路径有 $\min_k \mathcal{S}(Z^{(k)}) \leq \mathbb{E}[\|x_1 - x_0\|^2]/K$。

**图 6：Reflow 的示意图。** 路径随 Rectify 步骤逐步变直。

**III. 与最优传输的联系。** 直线耦合在最优传输（OT）意义下未必最优。二次成本最优传输的标志是粒子沿直线运动；但并非每个生成直线路径的映射都是最优的——最优性还依赖正确的端点映射。例如，恒等耦合为同分布下的 $c$-最优耦合；旋转给出的直线耦合并非 $c$-最优。

---

## 4.5 本章小结

本章阐明了扩散模型的第三个也是最后一个基础视角，即建立在确定性流原理之上的流视角。我们从归一化流（NFs）出发，它利用变量替换公式学习简单先验与数据分布之间的精确、可逆映射；随后看到该概念在神经常微分方程中演化为连续时间过程，由学到的速度场刻画变换，但该方式有一大缺点：训练循环中需要昂贵的 ODE 仿真。

**流匹配（FM）**的现代框架被提出作为应对这一挑战的简洁、高效方案。通过预先定义概率路径 $\{p_t\}_t$ 以及满足连续性方程的相应速度场，FM 为 ODE 流建立了清晰的目标。关键的是，FM 采用了强有力的条件技巧，将匹配边缘速度场的不可处理问题转化为对已知条件速度的简单、易处理回归，使训练完全无仿真。该视角将扩散模型本身重述为学习确定性流、将高斯先验传输到数据分布的特例。

随着流视角的引入，我们对扩散建模三大概念支柱的概览至此完成。贯穿这一历程，一个显著模式浮现：尽管各自源于 VAEs、EBMs 或 NFs，每个框架都收敛到连续时间生成过程，并依赖条件策略实现易处理的学习。

下一章我们将最终把这些平行线索综合为统一框架：(1) 形式地证明变分、基于分数与基于流的视角在基本层面数学等价；(2) 说明 Fokker-Planck 方程如何作为统领三种视角下密度演化的普适法则。这一统一视角将提供对现代扩散范式的完整、系统理解。
